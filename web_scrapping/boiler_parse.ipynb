{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1d05951",
   "metadata": {},
   "source": [
    "quotes_to_scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a72b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1200a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(s: str) -> str:\n",
    "    return ''.join(filter(str.isdigit, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584c25e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://gazovikperm.ru/katalog.html\"\n",
    "url_base = \"https://gazovikperm.ru/\"\n",
    "r = requests.post(url)\n",
    "html_doc = r.text\n",
    "soup = BeautifulSoup(html_doc, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2705e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mas = []\n",
    "caterory_inner_images = soup.find('div', class_=\"caterory_inner_images\")\n",
    "hrefs = caterory_inner_images.find_all('a')\n",
    "for href in hrefs:\n",
    "    # print(href['href'])\n",
    "    ref1 = url_base + href['href'].replace('\\n', '')\n",
    "    r = requests.post(ref1)\n",
    "    html_doc = r.text\n",
    "    soup1 = BeautifulSoup(html_doc, 'lxml')\n",
    "    groups_1 = soup1.find('div', class_=\"caterory_inner_images\") # Каталог 2 порядка\n",
    "    hrefs1 = groups_1.find_all('a')\n",
    "    \n",
    "    for href1 in hrefs1:\n",
    "        try:\n",
    "            cur_len = 0\n",
    "            ref2 = url_base + href1['href'].replace('\\n', '') + f\"&offset={cur_len}\"\n",
    "            # print(ref2) \n",
    "            r = requests.post(ref2)\n",
    "            html_doc = r.text\n",
    "            soup2 = BeautifulSoup(html_doc, 'lxml')\n",
    "\n",
    "            name = soup2.find('main', class_=\"content_in content_in_semiwide\").find(\"h1\").text\n",
    "\n",
    "            len_max_ = soup2.find('p', class_=\"col col-10\")\n",
    "            if len_max_ == None:\n",
    "                continue\n",
    "            len_max = int(clean_string(len_max_.text))\n",
    "            cur_len = 0\n",
    "\n",
    "            while cur_len < len_max:\n",
    "                ref2 = url_base + href1['href'].replace('\\n', '') + f\"&offset={cur_len}\"\n",
    "                r = requests.post(ref2)\n",
    "                html_doc = r.text\n",
    "                soup2 = BeautifulSoup(html_doc, 'lxml')\n",
    "                items = soup2.find_all('div', class_= \"list-items\")\n",
    "                cur_len += len(items)\n",
    "                for item in items:\n",
    "                    # print(ref2)\n",
    "\n",
    "                    cost_ = item.find('span', class_=\"js-price-value\")\n",
    "                    if cost_ == None:\n",
    "                        cost_ = item.find('span', class_=\"js-item-disabled\")\n",
    "                        if cost_ == None:\n",
    "                            cost = \"\"\n",
    "                        else:\n",
    "                            cost = cost_.text\n",
    "                    else:\n",
    "                        cost = cost_.text\n",
    "                    title = item.find('a', class_=\"img\")['title']\n",
    "                    desc = item.find('div', class_=\"item-properties\")\n",
    "                    descs = desc.find_all('p')\n",
    "                    desc_dict = {}\n",
    "                    for p in descs:\n",
    "                        desc_dict[p.find('span', class_=\"l1\").text] = p.find('span', class_=\"l2\").text\n",
    "                    # print(desc_dict)\n",
    "                    res_mas.append([title, cost, desc_dict])\n",
    "            \n",
    "            df = pd.DataFrame(res_mas, columns= ['title', 'cost', 'desc_dict'])\n",
    "            df.to_csv(\n",
    "                f'./res_data_1/{name}.csv',\n",
    "                index=False,           # не записывать индекс\n",
    "                sep=',',              # разделитель\n",
    "                encoding='utf-8',     # кодировка\n",
    "                header=True,          # записать заголовки\n",
    "                na_rep='NULL'         # представление для NaN значений\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(ref2)\n",
    "            raise e\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e925dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
